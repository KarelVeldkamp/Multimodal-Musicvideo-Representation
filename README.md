# Mulimodal Music Video Recommendation

## Project Summary
This repository contains the code and trained models for the masters thesis project on learning multimodal representations for music videos using contrastive learning. The full paper is available [here](https://github.com/KarelVeldkamp/Multimodal-Musicvideo-Representation/blob/master/data/08_reporting/Multimodal%20Music%20Video%20Representation.pdf). We used multimodal contrastive deep learning to learn common embeddings for the audio waveforms and video files of roughly 100,000 music videos published on the XITE app. The embeddings were evaluated on the downstream tasks of genre classification and music tagging. The project was executed in close collaboration with XITE. The models were trained on the private XITE dataset. To be as transparant as possible, we provide a description of the XITE dataset and compare it to the publicly available MSD dataset [here](https://github.com/KarelVeldkamp/Multimodal-Musicvideo-Representation/blob/master/data/08_reporting/Data%20Exploration%20Appendix.pdf)

## Repository structure
The repository is structured as a Kedro (0.17.7) project, which is a framework for producing flexible and reproducible data pipelines. All functions used for contrastive learning are located in [the mmnet directory](https://github.com/KarelVeldkamp/Multimodal-Musicvideo-Representation/tree/master/src/thesis_project/mmnet). The code for the pipelines used for learning and downstream tasks can be found in [the pipelines directory](https://github.com/KarelVeldkamp/Multimodal-Musicvideo-Representation/tree/master/src/thesis_project/pipelines). And parameters and settings for the different pipelines are set in the [conf directory](https://github.com/KarelVeldkamp/Multimodal-Musicvideo-Representation/tree/master/conf). The data used for training the model is unfortunately not publicly available, since it consists of the music videos licenced by XITE. The list of million song dataset track id's of songs that were used for the downstream task of music tagging is available [here](https://github.com/KarelVeldkamp/Multimodal-Musicvideo-Representation/tree/master/data/08_reporting/msdids.txt)

![Model architecture](data/08_reporting/architecture.png)
